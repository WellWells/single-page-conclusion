<!doctypehtml><html lang="zh-Hant"class="scroll-smooth"><meta name="twitter:image"content="https://wellstsai.com/single-page-conclusion/%E9%99%8D%E4%BD%8EAI%E5%B9%BB%E8%A6%BA%E9%A2%A8%E9%9A%AA.%E8%A9%95%E4%BC%B0%E6%A9%9F%E5%88%B6%E6%94%B9%E8%89%AF%E8%88%87%E4%BF%A1%E5%BF%83%E7%9B%AE%E6%A8%99%E8%A8%AD%E8%A8%88.png"><meta name="twitter:description"content="從預訓練與後訓練兩大源頭探因，結合實證數據、評估基準檢視與信心目標設計，提出可衡量的改進策略與模擬驗證，讓AI系統更誠實可靠，降低幻覺風險。"><meta name="twitter:title"content="降低AI幻覺風險：評估機制改良與信心目標設計"><meta name="twitter:card"content="summary_large_image"><meta property="og:type"content="article"><meta property="og:site_name"content="WellWells"><meta property="og:image"content="https://wellstsai.com/single-page-conclusion/%E9%99%8D%E4%BD%8EAI%E5%B9%BB%E8%A6%BA%E9%A2%A8%E9%9A%AA.%E8%A9%95%E4%BC%B0%E6%A9%9F%E5%88%B6%E6%94%B9%E8%89%AF%E8%88%87%E4%BF%A1%E5%BF%83%E7%9B%AE%E6%A8%99%E8%A8%AD%E8%A8%88.png"><meta property="og:url"content="https://wellstsai.com/single-page-conclusion/%E9%99%8D%E4%BD%8EAI%E5%B9%BB%E8%A6%BA%E9%A2%A8%E9%9A%AA.%E8%A9%95%E4%BC%B0%E6%A9%9F%E5%88%B6%E6%94%B9%E8%89%AF%E8%88%87%E4%BF%A1%E5%BF%83%E7%9B%AE%E6%A8%99%E8%A8%AD%E8%A8%88.html"><meta property="og:description"content="從預訓練與後訓練兩大源頭探因，結合實證數據、評估基準檢視與信心目標設計，提出可衡量的改進策略與模擬驗證，讓AI系統更誠實可靠，降低幻覺風險。"><meta property="og:title"content="降低AI幻覺風險：評估機制改良與信心目標設計"><meta name="description"content="從預訓練與後訓練兩大源頭探因，結合實證數據、評估基準檢視與信心目標設計，提出可衡量的改進策略與模擬驗證，讓AI系統更誠實可靠，降低幻覺風險。"><meta charset="UTF-8"><meta name="viewport"content="width=device-width,initial-scale=1"><title>降低AI幻覺風險：評估機制改良與信心目標設計</title><script src="https://cdn.tailwindcss.com"></script><script src="https://cdn.jsdelivr.net/npm/chart.js"></script><link rel="preconnect"href="https://fonts.googleapis.com"><link rel="preconnect"href="https://fonts.gstatic.com"crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@400;500;700&display=swap"rel="stylesheet"><style>body{font-family:'Noto Sans TC',sans-serif;background-color:#f8fafc;color:#1e293b}.chart-container{position:relative;width:100%;max-width:600px;margin-left:auto;margin-right:auto;height:300px;max-height:400px}@media (min-width:768px){.chart-container{height:350px}}.glassmorphism{background:rgba(255,255,255,.5);backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px);border-bottom:1px solid rgba(203,213,225,.5)}.nav-link{transition:all .3s ease;position:relative}.nav-link:after{content:'';position:absolute;width:0;height:2px;display:block;margin-top:5px;right:0;background:#0ea5e9;transition:width .3s ease;-webkit-transition:width .3s ease}.nav-link:hover:after{width:100%;left:0;background-color:#0ea5e9}.active-nav-link{color:#0ea5e9;font-weight:700}.range-slider::-webkit-slider-thumb{-webkit-appearance:none;appearance:none;width:20px;height:20px;background:#0ea5e9;cursor:pointer;border-radius:50%;margin-top:-6px}.range-slider::-moz-range-thumb{width:20px;height:20px;background:#0ea5e9;cursor:pointer;border-radius:50%}.keyword{color:#0369a1;font-weight:500;cursor:pointer;position:relative;display:inline-block;padding-bottom:2px;text-decoration:none;outline:0}.keyword::after{content:'';position:absolute;left:0;bottom:0;width:100%;height:2px;background:linear-gradient(to right,#38bdf8,#a5f3fc);transform:scaleX(0);transform-origin:left;transition:transform 250ms ease-out}.keyword:focus-visible::after,.keyword:hover::after{transform:scaleX(1)}@media (prefers-reduced-motion:reduce){.keyword{text-decoration:underline;text-decoration-color:#38bdf8;text-underline-offset:2px;transition:none}.keyword::after{display:none}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JKC4KZLT26"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JKC4KZLT26")</script><body class="antialiased"><div id="modal-backdrop"class="fixed inset-0 bg-black bg-opacity-30 backdrop-blur-sm z-50 transition-opacity duration-300 ease-out opacity-0 pointer-events-none"></div><div id="modal"class="fixed inset-0 z-50 flex items-center justify-center p-4 transition-all duration-300 ease-out opacity-0 scale-95 pointer-events-none"><div class="w-full max-w-2xl bg-white/60 backdrop-blur-xl border border-white/20 rounded-2xl shadow-2xl p-6 md:p-8"><div class="flex justify-between items-center mb-4"><h3 id="modal-title"class="text-2xl font-bold text-slate-800"></h3><button id="modal-close-btn"class="text-slate-500 hover:text-slate-800 transition-colors"><svg class="w-6 h-6"fill="none"stroke="currentColor"viewBox="0 0 24 24"xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round"stroke-linejoin="round"stroke-width="2"d="M6 18L18 6M6 6l12 12"></path></svg></button></div><div id="modal-content"class="text-slate-700 space-y-4 prose max-w-none"></div></div></div><header class="sticky top-0 z-40 w-full glassmorphism"><nav class="max-w-5xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><div class="flex items-center"><span class="font-bold text-xl text-slate-700">降低AI幻覺風險—評估機制改良與信心目標設計</span></div><div class="hidden md:block"><div class="ml-10 flex items-baseline space-x-4"><a href="#problem"id="nav-problem"class="nav-link px-3 py-2 rounded-md text-sm font-medium text-slate-600 hover:text-slate-900">問題是什麼</a> <a href="#cause"id="nav-cause"class="nav-link px-3 py-2 rounded-md text-sm font-medium text-slate-600 hover:text-slate-900">根本原因</a> <a href="#evidence"id="nav-evidence"class="nav-link px-3 py-2 rounded-md text-sm font-medium text-slate-600 hover:text-slate-900">資料證據</a> <a href="#solution"id="nav-solution"class="nav-link px-3 py-2 rounded-md text-sm font-medium text-slate-600 hover:text-slate-900">解決之道</a></div></div></div></nav></header><main class="max-w-5xl mx-auto py-8 px-4 sm:px-6 lg:px-8"><section id="problem"class="min-h-screen flex flex-col justify-center items-center text-center py-20"><h1 class="text-4xl md:text-6xl font-bold tracking-tight mb-4 text-slate-800">什麼是 <span tabindex="0"class="keyword"data-keyword="ai-hallucination">AI 幻覺</span>？</h1><p class="mt-4 max-w-2xl text-lg text-slate-600">就像面對難題的學生，<span tabindex="0"class="keyword"data-keyword="llm">大型語言模型</span>在不確定時會猜測，產生貌似可信卻不正確的陳述。這種現象被稱為「幻覺」，它嚴重破壞了我們對 AI 的信任。<div class="mt-12 w-full max-w-2xl bg-white/50 rounded-2xl shadow-lg p-8 border border-slate-200"><p class="text-slate-700 mb-4">試試看！問一個模型它可能不知道答案的問題：<p class="text-lg font-semibold text-slate-800">「某位AI研究員的生日是哪天？」<div id="interactive-example"class="mt-6 space-y-3 text-left"><div class="p-4 bg-slate-100 rounded-lg"><p><strong class="text-slate-600">模型回應 1：</strong> <span class="font-mono text-slate-800">03-07</span></div><div class="p-4 bg-slate-100 rounded-lg"><p><strong class="text-slate-600">模型回應 2：</strong> <span class="font-mono text-slate-800">15-06</span></div><div class="p-4 bg-slate-100 rounded-lg"><p><strong class="text-slate-600">模型回應 3：</strong> <span class="font-mono text-slate-800">01-01</span></div></div><p class="mt-6 text-sm text-slate-500">（事實上，正確日期是在秋天。以上皆為幻覺。）</div></section><section id="cause"class="py-20"><h2 class="text-3xl md:text-4xl font-bold text-center text-slate-800">探究根本原因：幻覺的雙重起源</h2><p class="mt-4 max-w-3xl mx-auto text-center text-lg text-slate-600">報告指出，AI幻覺並非神秘現象。它的根源深植於模型的訓練與評估方式中。我們可以將其分為兩個階段來理解：錯誤如何在「<span tabindex="0"class="keyword"data-keyword="pre-training">預訓練</span>」中誕生，又為何在「<span tabindex="0"class="keyword"data-keyword="post-training">後訓練</span>」中持續存在。<div class="mt-16 grid grid-cols-1 md:grid-cols-2 gap-12"><div class="bg-white/50 p-8 rounded-2xl shadow-lg border border-slate-200"><h3 class="text-2xl font-bold text-slate-800 mb-4">Part A: 預訓練 — <span tabindex="0"class="keyword"data-keyword="statistical-origins">錯誤的統計起源</span></h3><p class="text-slate-600 mb-6">在預訓練階段，即使訓練資料完全正確，模型為了學習語言的統計規律，也會自然地產生錯誤。這可以理解為一個「這是否有效？」(Is-It-Valid, IIV) 的二元分類問題。如果模型無法準確區分事實與謬誤，它在產出內容時就必然會產生幻覺。<div class="space-y-4"><div><h4 class="font-semibold text-slate-700">主要錯誤因素：</h4><ul class="list-disc list-inside mt-2 text-slate-600 space-y-1"><li><strong>任意事實：</strong> 對於訓練資料中缺乏規律、僅出現一次的事實（如個人生日），模型很難學習，幻覺率接近於這些「單例」事實的比例。<li><strong>劣質模型：</strong> 模型的架構不適合處理某些任務（例如，用處理詞彙的模型去數字元），導致系統性錯誤。<li><strong>垃圾進，垃圾出 (GIGO)：</strong> 訓練資料中本身存在的錯誤會被模型學習並複製。</ul></div></div></div><div class="bg-white/50 p-8 rounded-2xl shadow-lg border border-slate-200"><h3 class="text-2xl font-bold text-slate-800 mb-4">Part B: 後訓練 — 評估的陷阱</h3><p class="text-slate-600 mb-6">在後訓練階段，模型會根據人類偏好進行微調。然而，目前主流的評估標準大多採用「<span tabindex="0"class="keyword"data-keyword="binary-scoring">二元評分</span>」（答對得1分，答錯或不答得0分）。這種機制無形中鼓勵模型在不確定時去「猜測」，而不是誠實地回答<span tabindex="0"class="keyword"data-keyword="idk">「我不知道」(IDK)</span>。<div class="chart-container"><canvas id="scoringChart"></canvas></div><div class="mt-4"><label for="guessProbability"class="block text-sm font-medium text-slate-700">調整猜對的機率：<span id="guessProbabilityValue"class="font-bold text-sky-500">10%</span></label> <input id="guessProbability"type="range"min="0"max="100"value="10"class="w-full h-2 bg-slate-200 rounded-lg appearance-none cursor-pointer range-slider"></div><p class="text-xs text-center text-slate-500 mt-2">在二元評分下，只要猜對的機率大於0，猜測的<span tabindex="0"class="keyword"data-keyword="expected-score">期望得分</span>就永遠不會低於承認不確定。</div></div></section><section id="evidence"class="py-20"><h2 class="text-3xl md:text-4xl font-bold text-center text-slate-800">資料證據：主流評估基準的現狀</h2><p class="mt-4 max-w-3xl mx-auto text-center text-lg text-slate-600">報告分析了多個業界最具影響力的語言模型評估基準，發現絕大多數都存在獎勵猜測的傾向。這種「懲罰不確定性」的風氣，是幻覺問題難以根除的社會技術原因。<div class="mt-12 overflow-x-auto"><div class="inline-block min-w-full py-2 align-middle"><div class="overflow-hidden shadow ring-1 ring-black ring-opacity-5 md:rounded-lg"><table class="min-w-full divide-y divide-slate-300"><thead class="bg-slate-50"><tr><th scope="col"class="py-3.5 pl-4 pr-3 text-left text-sm font-semibold text-slate-900 sm:pl-6">基準名稱<th scope="col"class="px-3 py-3.5 text-left text-sm font-semibold text-slate-900">評分方式<th scope="col"class="px-3 py-3.5 text-center text-sm font-semibold text-slate-900">二元評分<th scope="col"class="px-3 py-3.5 text-center text-sm font-semibold text-slate-900">承認不確定性(IDK)得分<tbody class="divide-y divide-slate-200 bg-white"><tr><td class="whitespace-nowrap py-4 pl-4 pr-3 text-sm font-medium text-slate-900 sm:pl-6">GPQA<td class="whitespace-nowrap px-3 py-4 text-sm text-slate-500">多選題準確率<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-red-500 font-bold">是<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-slate-500">無<tr><td class="whitespace-nowrap py-4 pl-4 pr-3 text-sm font-medium text-slate-900 sm:pl-6">MMLU-Pro<td class="whitespace-nowrap px-3 py-4 text-sm text-slate-500">多選題準確率<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-red-500 font-bold">是<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-slate-500">無<tr><td class="whitespace-nowrap py-4 pl-4 pr-3 text-sm font-medium text-slate-900 sm:pl-6">IFEval<td class="whitespace-nowrap px-3 py-4 text-sm text-slate-500">指令遵循驗證<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-red-500 font-bold">是<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-slate-500">無<tr><td class="whitespace-nowrap py-4 pl-4 pr-3 text-sm font-medium text-slate-900 sm:pl-6">MATH<td class="whitespace-nowrap px-3 py-4 text-sm text-slate-500">等價性評分<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-red-500 font-bold">是<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-slate-500">無<tr><td class="whitespace-nowrap py-4 pl-4 pr-3 text-sm font-medium text-slate-900 sm:pl-6">SWE-bench<td class="whitespace-nowrap px-3 py-4 text-sm text-slate-500">程式碼修補程式通過單元測試<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-red-500 font-bold">是<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-slate-500">無<tr><td class="whitespace-nowrap py-4 pl-4 pr-3 text-sm font-medium text-slate-900 sm:pl-6">WildBench<td class="whitespace-nowrap px-3 py-4 text-sm text-slate-500">LM評分 rubric<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-green-600 font-bold">否<td class="whitespace-nowrap px-3 py-4 text-sm text-center text-slate-500">部分得分</table></div></div></div></section><section id="solution"class="py-20"><h2 class="text-3xl md:text-4xl font-bold text-center text-slate-800">解決之道：改變遊戲規則</h2><p class="mt-4 max-w-3xl mx-auto text-center text-lg text-slate-600">報告提出了一個務實的解決方案：修改現有的評估機制，引入「明確的信心目標」。這意味著在問題中明確指出錯誤的懲罰，從而使模型在信心不足時，選擇承認不確定性成為理性的最佳策略。<div class="mt-12 w-full max-w-3xl mx-auto bg-white/50 rounded-2xl shadow-lg p-8 border border-slate-200"><h3 class="text-xl font-bold text-center text-slate-800">模擬器：探索新的評分機制</h3><div class="mt-8 grid grid-cols-1 md:grid-cols-2 gap-8"><div><div class="mb-6"><label for="confidenceThreshold"class="block text-sm font-medium text-slate-700">1. 設定回答的<span tabindex="0"class="keyword"data-keyword="confidence-threshold">信心門檻 (t)</span></label><p class="text-xs text-slate-500">答錯的懲罰分數為 t / (1-t)</p><input id="confidenceThreshold"type="range"min="0"max="99"value="75"class="w-full h-2 bg-slate-200 rounded-lg appearance-none cursor-pointer mt-2 range-slider"><div class="text-center font-mono text-lg mt-1 text-slate-800"><span id="confidenceThresholdValue">75</span>%</div></div><div class="mb-6"><label for="modelConfidence"class="block text-sm font-medium text-slate-700">2. 假設模型的實際信心</label> <input id="modelConfidence"type="range"min="0"max="100"value="60"class="w-full h-2 bg-slate-200 rounded-lg appearance-none cursor-pointer mt-2 range-slider"><div class="text-center font-mono text-lg mt-1 text-slate-800"><span id="modelConfidenceValue">60</span>%</div></div></div><div class="flex flex-col justify-center items-center bg-slate-50 rounded-lg p-6"><p class="text-sm text-slate-600">答錯懲罰：<strong id="penaltyValue"class="text-xl text-red-500">-3.00</strong> 分<div class="w-full mt-4 space-y-3"><div id="strategyAnswer"class="p-3 rounded-lg border-2 border-slate-300"><p class="font-semibold">策略：回答<p class="text-sm">期望得分: <strong id="scoreAnswer"class="font-mono text-lg">-0.60</strong></div><div id="strategyIDK"class="p-3 rounded-lg border-2 border-slate-300"><p class="font-semibold">策略：承認不確定 (IDK)<p class="text-sm">期望得分: <strong class="font-mono text-lg">0.00</strong></div></div><p id="optimalStrategy"class="mt-4 text-center font-bold text-lg p-2 rounded-md">最佳策略：承認不確定</div></div></div><p class="mt-8 text-center text-slate-600">透過調整評分規則，我們可以引導AI系統變得更加誠實和可靠。</section></main><footer class="bg-slate-100 border-t border-slate-200 mt-16"><div class="max-w-5xl mx-auto py-8 px-4 sm:px-6 lg:px-8 text-center text-sm text-slate-500"><p class="mb-2">此報告根據 論文《Why Language Models Hallucinate》建立。</p><a href="https://wellstsai.com"target="_blank"rel="noopener noreferrer"class="text-slate-600 hover:text-sky-500 transition-colors duration-300">Generated by wellstsai.com</a><p class="mt-2 text-xs text-slate-400">撰寫日期：2025年9月16日</div></footer><script>document.addEventListener("DOMContentLoaded",function(){const e={"ai-hallucination":{title:"AI 幻覺 (AI Hallucination)",content:"<p>指人工智慧模型（特別是大型語言模型）產生看似真實、流暢，但實際上是錯誤或無中生有的資訊。這種現象並非 AI 具有意識或感知，而是其統計預測機制的副產品。當模型在資料不足或面對不確定性的問題時，它會「猜測」出一個機率上最可能的答案，即使這個答案與事實不符。</p>"},llm:{title:"大型語言模型 (Large Language Model)",content:"<p>是一種基於巨量文本資料訓練的深度學習模型。它能理解和生成人類語言，執行翻譯、摘要、問答等多種任務。LLM 的核心是學習單詞和句子之間的統計關係，從而預測下一個最可能出現的詞。GPT-4、Claude 3 等都是著名的 LLM。</p>"},"pre-training":{title:"預訓練 (Pre-training)",content:"<p>這是訓練大型語言模型的第一個、也是最耗資源的階段。在這個階段，模型會閱讀網路上大量的公開文本（如維基百科、書籍、網站），學習通用的語言知識、語法結構和事實資訊。預訓練的目標不是完成特定任務，而是建立一個廣泛的語言理解基礎。</p>"},"post-training":{title:"後訓練 (Post-training)",content:"<p>在預訓練之後，模型會進入後訓練或「微調」(Fine-tuning) 階段。這個階段會使用更小、更高品質的特定資料集來訓練模型，使其適應特定任務（如客服對話、程式碼產生），並遵循人類的期望與指令。RLHF (人類回饋強化學習) 是後訓練中常用的一種技術。</p>"},"binary-scoring":{title:"二元評分 (Binary Scoring)",content:"<p>一種「非對即錯」的評分方式。在這種機制下，答案只有兩種結果：完全正確（例如得 1 分）或完全錯誤（得 0 分）。沒有中間地帶或部分分數。這種評分方式因為簡單明瞭而被廣泛用於各種考試和 AI 評估基準中，但它忽略了答案的細微差別，並可能懲罰表達不確定性的行為。</p>"},idk:{title:"我不知道 (I Don't Know)",content:"<p>在本報告的脈絡中，「IDK」代表模型明確表示「承認不確定性」的任何回應。這不只是一個字面上的「我不知道」，而是泛指模型選擇不提供確定性答案，而是誠實地表達其知識限制的行為。例如「我無法找到相關資訊」、「這個問題沒有確切答案」等都屬於 IDK 的範疇。一個理想的 AI 系統應該在沒有足夠把握時，選擇做出 IDK 回應，而不是產生幻覺。</p>"},"expected-score":{title:"期望得分 (Expected Score)",content:"<p>在機率論中，期望值是指一個隨機變數的平均值，也就是將每個可能結果的數值乘以其發生機率後的總和。在此處，「猜測的期望得分」計算方式為：(猜對的機率 × 答對得分) + (猜錯的機率 × 答錯得分)。它代表了在多次重複猜測行為後，平均每次能獲得的分數。</p>"},"statistical-origins":{title:"錯誤的統計起源",content:"<p>這個概念指出，AI 幻覺並非程式錯誤或邏輯缺陷，而是源於模型學習語言分布的統計本質。模型的核心任務是預測序列中下一個最可能的元素（例如單詞）。當面對訓練資料中稀疏或不存在的資訊時，模型會依賴已學到的統計模式來「填補空白」，產生一個在統計上「看似合理」但事實上錯誤的輸出。因此，幻覺是模型忠實執行其統計預測任務時的自然產物。</p>"},"confidence-threshold":{title:"信心門檻 (Confidence Threshold)",content:"<p>這是一個預先設定的機率值，用來決定模型是否應該回答一個問題。在報告提出的新評分機制中，模型只有在對答案的正確性信心超過這個門檻時，才應該作答。如果信心低於門檻，更理性的選擇是回答「我不知道」(IDK)，以避免因答錯而受到懲罰。這個門檻 (t) 直接決定了答錯的懲罰力度 (t / (1-t))，從而影響模型的決策策略。</p>"}},t=document.querySelectorAll("section"),n=document.querySelectorAll(".nav-link"),o=new IntersectionObserver((e,t)=>{e.forEach(e=>{if(e.isIntersecting){const t=e.target.getAttribute("id");n.forEach(e=>{e.classList.remove("active-nav-link"),e.href.includes(t)&&e.classList.add("active-nav-link")})}})},{root:null,rootMargin:"0px",threshold:.5});t.forEach(e=>{o.observe(e)}),n.forEach(e=>{e.addEventListener("click",function(e){e.preventDefault(),document.querySelector(this.getAttribute("href")).scrollIntoView({behavior:"smooth"})})});const s=document.getElementById("guessProbability"),d=document.getElementById("guessProbabilityValue"),a=document.getElementById("scoringChart").getContext("2d");let i=new Chart(a,{type:"bar",data:{labels:["承認不確定 (IDK)","猜測"],datasets:[{label:"期望得分",data:[0,.1],backgroundColor:["#94a3b8","#0ea5e9"],borderRadius:5}]},options:{responsive:!0,maintainAspectRatio:!1,indexAxis:"y",plugins:{legend:{display:!1},title:{display:!0,text:"二元評分下的策略期望值"}},scales:{x:{beginAtZero:!0,max:1,title:{display:!0,text:"分數"}}}}});function l(e){d.textContent=`${e}%`,i.data.datasets[0].data[1]=e/100,i.update()}s.addEventListener("input",e=>{l(e.target.value)}),l(s.value);const c=document.getElementById("confidenceThreshold"),r=document.getElementById("modelConfidence"),u=document.getElementById("confidenceThresholdValue"),m=document.getElementById("modelConfidenceValue"),y=document.getElementById("penaltyValue"),g=document.getElementById("scoreAnswer"),p=document.querySelector("#strategyIDK strong"),v=document.getElementById("optimalStrategy"),L=document.getElementById("strategyAnswer"),b=document.getElementById("strategyIDK");function E(){const e=c.value/100,t=r.value/100;u.textContent=`${Math.round(100*e)}`,m.textContent=`${Math.round(100*t)}`;let n=0;n=e<1?-e/(1-e):-1/0,y.textContent=n.toFixed(2);const o=1*t+(1-t)*n;g.textContent=o.toFixed(2);p.textContent=(0).toFixed(2),L.classList.remove("border-sky-500","bg-sky-50"),b.classList.remove("border-sky-500","bg-sky-50"),L.classList.add("border-slate-300"),b.classList.add("border-slate-300"),o>0?(v.textContent="最佳策略：回答",v.classList.remove("text-sky-600","bg-sky-100"),v.classList.add("text-orange-500","bg-orange-100"),L.classList.add("border-sky-500","bg-sky-50"),L.classList.remove("border-slate-300")):(v.textContent="最佳策略：承認不確定",v.classList.remove("text-orange-500","bg-orange-100"),v.classList.add("text-sky-600","bg-sky-100"),b.classList.add("border-sky-500","bg-sky-50"),b.classList.remove("border-slate-300"))}c.addEventListener("input",E),r.addEventListener("input",E),E();const I=document.getElementById("modal"),k=document.getElementById("modal-backdrop"),h=document.getElementById("modal-title"),x=document.getElementById("modal-content"),f=document.getElementById("modal-close-btn");function B(t){const n=e[t];n&&(h.textContent=n.title,x.innerHTML=n.content,document.body.classList.add("overflow-hidden"),k.classList.remove("opacity-0","pointer-events-none"),I.classList.remove("opacity-0","scale-95","pointer-events-none"))}function C(){document.body.classList.remove("overflow-hidden"),k.classList.add("opacity-0","pointer-events-none"),I.classList.add("opacity-0","scale-95","pointer-events-none")}document.querySelectorAll(".keyword").forEach(e=>{e.addEventListener("click",t=>{t.preventDefault(),B(e.dataset.keyword)}),e.addEventListener("keydown",t=>{"Enter"!==t.key&&" "!==t.key||(t.preventDefault(),B(e.dataset.keyword))})}),f.addEventListener("click",C),k.addEventListener("click",C),window.addEventListener("keydown",e=>{"Escape"!==e.key||I.classList.contains("pointer-events-none")||C()})})</script>