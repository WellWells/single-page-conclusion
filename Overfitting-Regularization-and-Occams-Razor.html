<!doctypehtml><html lang="en"><meta name="twitter:image"content="https://wellstsai.com/single-page-conclusion/Overfitting-Regularization-and-Occams-Razor.png"><meta name="twitter:description"content="This interactive lab explains overfitting in machine learning. Adjust parameters like polynomial degree and regularization to see how model complexity affects training error versus generalization, illustrating Occam's Razor."><meta name="twitter:title"content="Overfitting, Regularization, and Occam's Razor"><meta name="twitter:card"content="summary_large_image"><meta property="og:type"content="article"><meta property="og:site_name"content="WellWells"><meta property="og:image"content="https://wellstsai.com/single-page-conclusion/Overfitting-Regularization-and-Occams-Razor.png"><meta property="og:url"content="https://wellstsai.com/single-page-conclusion/Overfitting-Regularization-and-Occams-Razor.html"><meta property="og:description"content="This interactive lab explains overfitting in machine learning. Adjust parameters like polynomial degree and regularization to see how model complexity affects training error versus generalization, illustrating Occam's Razor."><meta property="og:title"content="Overfitting, Regularization, and Occam's Razor"><meta name="description"content="This interactive lab explains overfitting in machine learning. Adjust parameters like polynomial degree and regularization to see how model complexity affects training error versus generalization, illustrating Occam's Razor."><meta charset="utf-8"><meta name="viewport"content="width=device-width,initial-scale=1"><title>Overfitting, Regularization, and Occam's Razor</title><script src="https://cdn.tailwindcss.com"></script><style>:root{--bg-start-rgb:15,23,42;--bg-end-rgb:30,41,59;--card-bg-rgb:23,28,47;--accent-glow:110,168,254;--accent-2-glow:126,231,135}body{background-color:rgb(var(--bg-start-rgb));background-image:radial-gradient(at 20% 20%,rgba(var(--accent-glow),.15) 0,transparent 50%),radial-gradient(at 80% 80%,rgba(var(--accent-2-glow),.1) 0,transparent 50%);font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Noto Sans","Helvetica Neue",Helvetica,Arial,sans-serif}.glass-card{background-color:rgba(var(--card-bg-rgb),.6);backdrop-filter:blur(12px);-webkit-backdrop-filter:blur(12px);border:1px solid rgba(255,255,255,.1);box-shadow:0 8px 32px 0 rgba(0,0,0,.37)}.gradient-text{background-image:linear-gradient(120deg,#89f7fe 0,#66a6ff 100%);-webkit-background-clip:text;background-clip:text;-webkit-text-fill-color:transparent}.fade-in-section{opacity:0;transform:translateY(20px);transition:opacity .6s ease-out,transform .6s ease-out}.fade-in-section.is-visible{opacity:1;transform:translateY(0)}#modal-backdrop{transition:opacity .3s ease}#modal-content{transition:opacity .3s ease,transform .3s ease}.keyword-modal{color:#93c5fd;cursor:pointer;border-bottom:1px dotted #60a5fa;transition:all .2s ease-in-out}.keyword-modal:hover{background-color:rgba(96,165,250,.2);border-bottom-style:solid}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JKC4KZLT26"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-JKC4KZLT26")</script><body class="bg-slate-900 text-slate-200 antialiased"><header class="py-8 px-4 text-center"><h1 class="gradient-text text-4xl md:text-5xl font-bold tracking-tight">Overfitting: Why a Perfect Explanation is Often Useless</h1><p class="mt-4 max-w-2xl mx-auto text-slate-400">Have you ever had this experience: you study for an exam by grinding through practice questions, and your performance improves at first, only to get worse as you do more? This phenomenon is rooted in a profound concept called <strong><span class="keyword-modal"data-term="overfitting">Overfitting</span></strong>. This interactive page will let you experience it firsthand and understand why "simplicity is the ultimate sophistication" is not just a philosophical idea but a core principle of data science.</header><main class="p-4 md:p-6 max-w-7xl mx-auto grid gap-6 grid-cols-12"><section class="fade-in-section glass-card col-span-12 lg:col-span-8 rounded-2xl p-6"><h2 class="flex items-center gap-3 text-2xl font-bold text-white"><div class="w-8 h-8 rounded-full bg-gradient-to-br from-sky-400 to-blue-600 flex-shrink-0"></div>1. Data Fitting Lab: From Underfitting to Overfitting</h2><div class="mt-4 text-sm text-slate-400 flex flex-wrap gap-x-4 gap-y-2 items-center"><span class="flex items-center gap-2"><div class="w-3 h-3 rounded-sm bg-slate-300"></div>True Function </span><span class="flex items-center gap-2"><div class="w-3 h-3 rounded-sm bg-sky-400"></div>Observed Data </span><span class="flex items-center gap-2"><div class="w-3 h-3 rounded-sm bg-green-400"></div>Model Prediction </span><span id="diagnosis"class="inline-block px-3 py-1 text-xs rounded-full bg-slate-700/50 border border-slate-600">Diagnosis: —</span></div><div class="mt-4 p-2 border border-slate-700 rounded-lg bg-slate-900/50"><canvas id="chart"width="1000"height="380"aria-label="Fitting Chart"class="w-full"></canvas></div><div class="mt-4 grid grid-cols-1 md:grid-cols-2 gap-4"><div class="p-4 bg-slate-900/50 border border-slate-700 rounded-lg"><h4 class="text-sm text-slate-400">Training <span class="keyword-modal"data-term="mse">MSE</span> (on Observed Data)</h4><p id="mse-train"class="font-mono text-lg text-white">—</div><div class="p-4 bg-slate-900/50 border border-slate-700 rounded-lg"><h4 class="text-sm text-slate-400"><span class="keyword-modal"data-term="generalization">Generalization</span> <span class="keyword-modal"data-term="mse">MSE</span> (on True Function)</h4><p id="mse-test"class="font-mono text-lg text-white">—</div></div><h3 class="mt-6 text-xl font-semibold text-white">Parameters</h3><div class="mt-4 space-y-4"><div class="grid grid-cols-[180px_1fr_90px] gap-4 items-center"><label for="deg"class="text-slate-300"><span class="keyword-modal"data-term="degree">Polynomial Degree</span> (Complexity)</label><input id="deg"type="range"min="0"max="11"value="3"><span id="deg-val"class="text-center font-mono px-3 py-1 rounded-md bg-slate-700 text-white">3</span></div><div class="grid grid-cols-[180px_1fr_90px] gap-4 items-center"><label for="lambda"class="text-slate-300"><span class="keyword-modal"data-term="lambda">Regularization Strength λ</span></label><input id="lambda"type="range"min="-6"max="3"value="-2"><span id="lambda-val"class="text-center font-mono px-3 py-1 rounded-md bg-slate-700 text-white">10^-2</span></div><div class="grid grid-cols-[180px_1fr_90px] gap-4 items-center"><label for="noise"class="text-slate-300"><span class="keyword-modal"data-term="noise">Noise Amplitude</span></label><input id="noise"type="range"min="0"max="6"step="0.1"value="1.8"><span id="noise-val"class="text-center font-mono px-3 py-1 rounded-md bg-slate-700 text-white">1.8</span></div><div class="grid grid-cols-[180px_1fr_90px] gap-4 items-center"><label for="npts"class="text-slate-300">Sample Size (Months)</label><input id="npts"type="range"min="5"max="24"value="12"><span id="npts-val"class="text-center font-mono px-3 py-1 rounded-md bg-slate-700 text-white">12</span></div></div><div class="mt-6 flex flex-wrap gap-3 items-center"><button id="resample"class="px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors">Resample</button> <button id="jitter"class="px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors">Jitter Data</button> <button id="reset"class="px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors">Reset Parameters</button> <span class="text-xs text-slate-500">Hint: With 12 data points, an 11th-degree polynomial can pass through every point perfectly.</span></div><details class="mt-4 p-4 bg-slate-900/50 border border-slate-700 rounded-lg"><summary class="cursor-pointer text-slate-300">View <span class="keyword-modal"data-term="coefficients">Coefficients</span> & Complexity (<span class="keyword-modal"data-term="l2norm">L2 Norm</span>)</summary><div id="coeffs"class="mt-4"></div></details></section><section class="fade-in-section glass-card col-span-12 lg:col-span-4 rounded-2xl p-6"><h2 class="flex items-center gap-3 text-2xl font-bold text-white"><div class="w-8 h-8 rounded-full bg-gradient-to-br from-green-400 to-teal-600 flex-shrink-0"></div>Concepts & Guide</h2><div class="mt-4 space-y-4 text-slate-300"><p><strong>How to Use:</strong><ol class="list-decimal list-inside space-y-2 text-sm"><li><strong>Feel Complexity:</strong> Set "Regularization Strength λ" to its minimum, then slowly drag the "Polynomial Degree" slider from 0 to 11.<li><strong>Observe <span class="keyword-modal"data-term="overfitting">Overfitting</span>:</strong> As the degree increases, the "Training <span class="keyword-modal"data-term="mse">MSE</span>" drops, but the curve becomes wildly distorted, causing the "<span class="keyword-modal"data-term="generalization">Generalization</span> <span class="keyword-modal"data-term="mse">MSE</span>" to skyrocket.<li><strong>Feel <span class="keyword-modal"data-term="regularization">Regularization</span>:</strong> At a high degree, increasing λ will "pull" the curve back to a smoother, simpler shape.<li><strong>Understand <span class="keyword-modal"data-term="occam">Occam's Razor</span>:</strong> Among multiple explanations, choose the simplest one (e.g., a 3rd-degree polynomial), as it often generalizes better.</ol><hr class="border-slate-700"><p class="text-xs text-slate-400">True function on this page:<br><code class="font-mono bg-slate-800/50 p-1 rounded">f(x) = 15 + 10·sin(2π·(x-3)/12)</code></div></section><section class="fade-in-section glass-card col-span-12 lg:col-span-6 rounded-2xl p-6"><h2 class="flex items-center gap-3 text-2xl font-bold text-white"><div class="w-8 h-8 rounded-full bg-gradient-to-br from-amber-400 to-orange-600 flex-shrink-0"></div>2. The "Find the Pattern" Quiz</h2><p class="mt-4 text-slate-400">The core of <span class="keyword-modal"data-term="overfitting">overfitting</span> is ignoring "complexity". The answers to the following questions are rooted in psychology, not pure mathematics.<div class="mt-4 space-y-6"><div><h3 class="font-semibold text-slate-200">Question A: <code>1, 3, 5, 7, ?</code></h3><div class="mt-2 flex gap-3"><button class="ans px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors"data-q="A"data-val="9">Answer: 9</button><button class="ans px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors"data-q="A"data-val="114514">Answer: 114514</button></div><p id="ex-A"class="mt-2 text-sm text-slate-500">—</div><div><h3 class="font-semibold text-slate-200">Question B: <code>2, 4, 8, 16, 31, ?</code></h3><div class="mt-2 flex gap-3"><button class="ans px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors"data-q="B"data-val="?">I can't guess</button><button class="ans px-4 py-2 bg-slate-700/50 border border-slate-600 rounded-lg hover:bg-slate-700 transition-colors"data-q="B"data-val="57">Answer: 57</button></div><p id="ex-B"class="mt-2 text-sm text-slate-500">—<details class="mt-2"><summary class="text-xs text-slate-400 cursor-pointer">Hint: View the full sequence</summary><p class="note mt-2 text-xs">The full sequence for n=1 to 8 is: <code>1, 2, 4, 8, 16, 31, 57, 99</code></details></div></div></section><section class="fade-in-section glass-card col-span-12 lg:col-span-6 rounded-2xl p-6"><h2 class="flex items-center gap-3 text-2xl font-bold text-white"><div class="w-8 h-8 rounded-full bg-gradient-to-br from-purple-500 to-indigo-700 flex-shrink-0"></div>3. Overfitting in Life & Takeaways</h2><ul class="mt-4 list-disc list-inside space-y-2 text-slate-300"><li><strong>Cramming for Exams:</strong> Memorizing specific details from past exams, treating exceptions as rules, and failing to adapt to new question formats.<li><strong>Stereotypes:</strong> Forming complex, rigid opinions about a group based on limited encounters, ignoring individual variation.<li><strong>Historical Explanations:</strong> Using a perfect theory to explain every past event as "inevitable," yet failing spectacularly when predicting the future.</ul><hr class="my-4 border-slate-700"><h3 class="font-semibold text-slate-200">Learning Principles</h3><ul class="mt-2 list-disc list-inside space-y-2 text-slate-300"><li><strong>Learning without thought → <span class="keyword-modal"data-term="underfitting">Underfitting</span>:</strong> The model is too simple to capture the trend.<li><strong>Thought without learning → <span class="keyword-modal"data-term="overfitting">Overfitting</span>:</strong> Inventing complex theories that perform poorly on new data.<li><strong>Allowing for error is a necessary cost:</strong> Chasing a "perfect explanation" of the past often sacrifices the ability to predict the future.</ul></section></main><footer class="fade-in-section mt-8 py-8 text-center bg-slate-900/50 border-t border-slate-800"><p class="text-sm text-slate-500"><a href="https://wellstsai.com"target="_blank"rel="noopener noreferrer"class="hover:text-sky-400 transition-colors">Generated by wellstsai.com</a></footer><div id="modal-backdrop"class="fixed inset-0 bg-black/70 backdrop-blur-sm z-40 opacity-0 pointer-events-none"></div><div id="modal-container"class="fixed inset-0 z-50 flex items-center justify-center p-4 opacity-0 pointer-events-none"><div id="modal-content"class="glass-card w-full max-w-md rounded-2xl p-6 transform scale-95"><div class="flex justify-between items-center"><h3 id="modal-title"class="text-2xl font-bold gradient-text"></h3><button id="modal-close"class="text-slate-400 hover:text-white transition-colors">&times;</button></div><div id="modal-body"class="mt-4 text-slate-300"></div></div></div><script>const linspace=(e,t,n)=>Array.from({length:n},(s,o)=>e+(t-e)*o/(n-1)),transpose=e=>e[0].map((t,n)=>e.map(e=>e[n])),matmul=(e,t)=>{const n=e.length,s=e[0].length,o=t[0].length,i=Array.from({length:n},()=>Array(o).fill(0));for(let a=0;a<n;a++)for(let n=0;n<s;n++){const s=e[a][n];for(let e=0;e<o;e++)i[a][e]+=s*t[n][e]}return i},add=(e,t)=>e.map((e,n)=>e.map((e,s)=>e+t[n][s])),eye=e=>Array.from({length:e},(t,n)=>Array.from({length:e},(e,t)=>n===t?1:0));function inv(e){const t=e.length,n=e.map(e=>e.slice()),s=eye(t);for(let e=0;e<t;e++){let o=e;for(let s=e+1;s<t;s++)Math.abs(n[s][e])>Math.abs(n[o][e])&&(o=s);if(Math.abs(n[o][e])<1e-12)throw new Error("Matrix is singular, please adjust λ or degree");[n[e],n[o]]=[n[o],n[e]],[s[e],s[o]]=[s[o],s[e]];const i=n[e][e];for(let o=0;o<t;o++)n[e][o]/=i,s[e][o]/=i;for(let o=0;o<t;o++){if(o===e)continue;const i=n[o][e];for(let a=0;a<t;a++)n[o][a]-=i*n[e][a],s[o][a]-=i*s[e][a]}}return s}const mse=(e,t)=>e.reduce((e,n,s)=>e+(n-t[s])**2,0)/t.length;function trueFunc(e){return 15+10*Math.sin(2*Math.PI*(e-3)/12)}function makeData(e,t,n=!0){const s=n?Array.from({length:e},()=>12*Math.random()):linspace(0,11,e),o=s.map(e=>trueFunc(e)+(2*Math.random()-1)*t);return{xs:s,ys:o}}function vandermonde(e,t){return e.map(e=>{const n=[];for(let s=0;s<=t;s++)n.push(e**s);return n})}function ridgeFit(e,t,n,s){const o=vandermonde(e,n),i=t.map(e=>[e]),a=transpose(o),l=matmul(a,o),r=l.length,c=eye(r).map((e,t)=>e.map((e,n)=>t===n?e*s:0)),d=add(l,c),m=matmul(a,i),g=inv(d),h=matmul(g,m).map(e=>e[0]),u=Math.sqrt(h.reduce((e,t)=>e+t*t,0));return{w:h,l2:u}}function predict(e,t){let n=0;for(let s=0;s<e.length;s++)n+=e[s]*t**s;return n}const canvas=document.getElementById("chart"),ctx=canvas.getContext("2d");function drawChart(e){const{xs:t,ys:n,w:s,deg:o}=e,i=linspace(0,12,300),a=i.map(e=>trueFunc(e)),l=i.map(e=>predict(s,e)),r=[...n,...a,...l].filter(e=>isFinite(e));if(0===r.length)return;const c=Math.min(...r)-2,d=Math.max(...r)+2,m=40,g=canvas.width,h=canvas.height,u=e=>m+(e-0)/12*(g-80),p=e=>h-m-(e-c)/(d-c)*(h-80);ctx.clearRect(0,0,g,h),ctx.strokeStyle="rgba(71, 85, 105, 0.5)",ctx.lineWidth=1,ctx.beginPath();for(let e=0;e<=12;e+=1){const t=u(e);ctx.moveTo(t,m),ctx.lineTo(t,h-m)}for(let e=5*Math.ceil(c/5);e<=d;e+=5){const t=p(e);ctx.moveTo(m,t),ctx.lineTo(g-m,t)}ctx.stroke(),ctx.strokeStyle="rgba(148, 163, 184, 0.8)",ctx.lineWidth=1.2,ctx.beginPath(),ctx.moveTo(m,h-m),ctx.lineTo(g-m,h-m),ctx.moveTo(m,m),ctx.lineTo(m,h-m),ctx.stroke(),ctx.fillStyle="rgb(148, 163, 184)",ctx.textAlign="center",ctx.font="12px ui-sans-serif,system-ui";for(let e=0;e<=12;e+=1)ctx.fillText(String(e),u(e),h-m+14);ctx.textAlign="right";for(let e=5*Math.ceil(c/5);e<=d;e+=5)ctx.fillText(String(e),34,p(e)+4);ctx.strokeStyle="rgb(203, 213, 225)",ctx.lineWidth=2,ctx.beginPath(),i.forEach((e,t)=>{const n=u(e),s=p(a[t]);0===t?ctx.moveTo(n,s):ctx.lineTo(n,s)}),ctx.stroke(),ctx.strokeStyle="rgb(52, 211, 153)",ctx.lineWidth=2.2,ctx.beginPath(),i.forEach((e,t)=>{const n=l[t];if(!isFinite(n))return;const s=u(e),o=p(n);0===t?ctx.moveTo(s,o):ctx.lineTo(s,o)}),ctx.stroke(),ctx.fillStyle="rgb(56, 189, 248)",t.forEach((e,t)=>{const s=u(e),o=p(n[t]);ctx.beginPath(),ctx.arc(s,o,4,0,2*Math.PI),ctx.fill()}),ctx.fillStyle="rgb(226, 232, 240)",ctx.font="13px ui-sans-serif,system-ui",ctx.fillText(`Degree d = ${o}`,g-80,28)}const $=e=>document.querySelector(e),degEl=$("#deg"),lamEl=$("#lambda"),noiseEl=$("#noise"),nEl=$("#npts"),degVal=$("#deg-val"),lamVal=$("#lambda-val"),noiseVal=$("#noise-val"),nVal=$("#npts-val"),mseTrainEl=$("#mse-train"),mseTestEl=$("#mse-test"),diagnosisEl=$("#diagnosis"),coeffsEl=$("#coeffs");let DATA=makeData(12,1.8,!0),STATE={xs:DATA.xs,ys:DATA.ys,deg:3,lambda:.01,w:[0],l2:0};function refresh(){const e=parseInt(degEl.value,10),t=10**parseInt(lamEl.value,10),n=parseFloat(noiseEl.value),s=parseInt(nEl.value,10);(s!==STATE.xs.length||Math.abs(n-STATE.noise)>1e-9)&&(DATA=makeData(s,n,!0));const{xs:o,ys:i}=DATA;let a,l=!1;try{if(a=ridgeFit(o,i,e,t),a.w.some(e=>!isFinite(e)))throw new Error("Calculation resulted in invalid numbers (NaN/Infinity)")}catch(t){l=!0,a={w:Array(e+1).fill(0),l2:NaN},console.error("Fit calculation failed:",t.message)}const r=a.w,c=a.l2,d=o.map(e=>predict(r,e)),m=mse(d,i),g=linspace(0,12,200),h=g.map(e=>predict(r,e)),u=g.map(e=>trueFunc(e)),p=mse(h,u);STATE={xs:o,ys:i,deg:e,lambda:t,w:r,l2:c,noise:n},drawChart(STATE),mseTrainEl.textContent=isFinite(m)?m.toFixed(3):"Calc Failed",mseTestEl.textContent=isFinite(p)?p.toFixed(3):"Calc Failed",degVal.textContent=`${e}`,lamVal.textContent=`10^${lamEl.value}`,noiseVal.textContent=`${n.toFixed(1)}`,nVal.textContent=`${o.length}`;let f="",x="Balanced";l?(f="bad",x="Calc Failed (Unstable)"):m<5&&p>8&&p>4*m&&e>=5&&t<.1?(f="bad",x="Overfitting (Low train error, poor generalization)"):m>15&&p>15&&e<=3?(f="warn",x="Underfitting (Model too simple)"):p<8&&Math.abs(p-m)<5&&(f="good",x="Good Generalization"),diagnosisEl.className="inline-block px-3 py-1 text-xs rounded-full border "+("bad"===f?"bg-red-900/50 border-red-700 text-red-200":"warn"===f?"bg-amber-900/50 border-amber-700 text-amber-200":"good"===f?"bg-green-900/50 border-green-700 text-green-200":"bg-slate-700/50 border-slate-600"),diagnosisEl.textContent=`Diagnosis: ${x}`;const y=l?'<tr><td colspan="2" style="text-align:center; color:var(--bad);">Calculation Failed</td></tr>':STATE.w.map((e,t)=>`<tr><td class="text-left text-slate-400">w<sub>${t}</sub></td><td class="text-white">${e.toExponential(4)}</td></tr>`).join("");coeffsEl.innerHTML=`<div class="grid grid-cols-2 gap-4 mb-2"><div class="p-3 bg-slate-800/50 rounded-lg"><h4 class="text-xs text-slate-400">Coefficient L2 Norm</h4><p class="font-mono text-sm text-white">${isNaN(c)?"—":c.toExponential(3)}</p></div><div class="p-3 bg-slate-800/50 rounded-lg"><h4 class="text-xs text-slate-400">Regularization λ</h4><p class="font-mono text-sm text-white">${t.toExponential(2)}</p></div></div><table class="w-full text-xs"><thead><tr><th class="text-left font-normal text-slate-400">Index</th><th class="text-right font-normal text-slate-400">Value</th></tr></thead><tbody class="divide-y divide-slate-800">${y||""}</tbody></table><p class="mt-2 text-xs text-slate-500">Note: Ridge regularization penalizes the size of coefficients (L2 Norm) to prefer smoother, simpler curves.</p>`}function explainA(e){const t=$("#ex-A");t.innerHTML="9"===e?"You chose the <strong>simple arithmetic sequence</strong> (+2). Without more constraints, preferring a simple solution (Occam's Razor) is the most reasonable strategy.":"You chose the 'brute-force' answer from a <strong>high-degree polynomial</strong>. For example, the following 4th-degree polynomial fits perfectly:<br><code class=\"text-xs break-all block bg-slate-800/50 p-2 rounded mt-1\">f(x) = (114505/24)x⁴ - ...</code><br>Reminder: Without limiting model complexity, any next term can be perfectly fitted by some complex model."}function explainB(e){const t=$("#ex-B");t.innerHTML="57"===e?'Correct! The pattern is from "dividing a circle," which gives the maximum number of regions created by connecting n points on a circle. The next term (for n=7) is indeed <strong>57</strong>.<br>The formula is:<div class="my-2 p-2 bg-slate-800/50 rounded text-center font-mono text-slate-300 text-sm">R(n) = C(n, 4) + C(n, 2) + 1</div>':"Your intuition is correct. With insufficient information, countless patterns are possible. More terms or background context are needed to find a unique answer."}degEl.addEventListener("input",refresh),lamEl.addEventListener("input",refresh),noiseEl.addEventListener("input",refresh),nEl.addEventListener("input",refresh),$("#resample").addEventListener("click",()=>{DATA=makeData(parseInt(nEl.value,10),parseFloat(noiseEl.value),!0),refresh()}),$("#jitter").addEventListener("click",()=>{const{xs:e,ys:t}=DATA;if(e.length<2)return;const n=new Set;for(;n.size<2;)n.add(Math.floor(Math.random()*e.length));n.forEach(e=>t[e]+=(Math.random()<.5?-1:1)*(3+5*Math.random())),refresh()}),$("#reset").addEventListener("click",()=>{degEl.value=3,lamEl.value=-2,noiseEl.value=1.8,nEl.value=12,DATA=makeData(12,1.8,!0),refresh()}),document.querySelectorAll(".ans").forEach(e=>{e.addEventListener("click",e=>{const t=e.target.dataset.q,n=e.target.dataset.val;"A"===t?explainA(n):explainB(n)})}),document.addEventListener("DOMContentLoaded",()=>{const e=new IntersectionObserver(t=>{t.forEach((t,n)=>{t.isIntersecting&&(t.target.style.transitionDelay=100*n+"ms",t.target.classList.add("is-visible"),e.unobserve(t.target))})},{threshold:.1});document.querySelectorAll(".fade-in-section").forEach(t=>{e.observe(t)});const t=$("#modal-backdrop"),n=$("#modal-container"),s=$("#modal-content"),o=$("#modal-title"),i=$("#modal-body"),a=$("#modal-close"),l={overfitting:{title:"Overfitting",body:'<p>A phenomenon where a model performs exceptionally well on training data but poorly on new, unseen data.</p><strong class="text-slate-200 mt-3 block">In-depth Analysis:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li><strong>Cause:</strong> The model learns specific details and noise from the training data, rather than the underlying pattern.</li><li><strong>Symptom:</strong> Very low training error but high testing error.</li><li><strong>Solutions:</strong> Regularization, early stopping, cross-validation, adding more data.</li></ul><strong class="text-slate-200 mt-3 block">Why is a perfect explanation useless?</strong><p class="text-sm">A model that perfectly explains all training data is treating specific cases as general rules. This "perfection" reveals the model\'s lack of true understanding. A valuable model must be able to generalize.</p>'},underfitting:{title:"Underfitting",body:'<p>A situation where a model is too simple to capture the underlying patterns in the data.</p><strong class="text-slate-200 mt-3 block">In-depth Analysis:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li><strong>Cause:</strong> Insufficient model complexity or poor feature selection.</li><li><strong>Symptom:</strong> Both training and testing errors are high.</li><li><strong>Solutions:</strong> Increase model complexity, add more features, reduce regularization.</li></ul>'},generalization:{title:"Generalization",body:'<p>The ability of a model to perform well on new, unseen data.</p><strong class="text-slate-200 mt-3 block">In-depth Analysis:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li><strong>Importance:</strong> The key metric for a model\'s practical value.</li><li><strong>Evaluation:</strong> Assessed using a test set or cross-validation.</li><li><strong>Influencers:</strong> Model complexity, data quality, feature selection.</li></ul>'},mse:{title:"MSE (Mean Squared Error)",body:'<p>The most common loss function used in regression problems.</p><strong class="text-slate-200 mt-3 block">Core Formula:</strong><div class="my-2 p-2 bg-slate-800/50 rounded text-center font-mono text-slate-300 text-sm">MSE = (1/n) Σ(yᵢ - ŷᵢ)²</div><strong class="text-slate-200 mt-3 block">In-depth Analysis:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li><strong>Property:</strong> Penalizes larger errors more heavily; differentiable.</li><li><strong>Drawback:</strong> Sensitive to outliers.</li></ul>'},degree:{title:"Polynomial Degree",body:'<p>The highest exponent in a polynomial model, which determines its complexity and fitting ability.</p><strong class="text-slate-200 mt-3 block">The Trade-off:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li>A degree that is too low causes <strong>underfitting</strong>.</li><li>A degree that is too high causes <strong>overfitting</strong>.</li><li>The optimal degree is often chosen via cross-validation.</li></ul>'},lambda:{title:"Regularization Strength λ (Lambda)",body:'<p>A hyperparameter that controls the extent of the regularization penalty on the loss function.</p><strong class="text-slate-200 mt-3 block">Mechanism:</strong><div class="my-2 p-2 bg-slate-800/50 rounded text-center font-mono text-slate-300 text-sm">Loss = MSE + λ × Regularization Term</div><strong class="text-slate-200 mt-3 block">Effect:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li>The larger the λ, the stronger the regularization, and the simpler the model.</li><li>If λ = 0, there is no regularization.</li></ul>'},noise:{title:"Noise Amplitude",body:'<p>The intensity or range of random fluctuations in the data.</p><strong class="text-slate-200 mt-3 block">In-depth Analysis:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li><strong>Sources:</strong> Measurement errors, environmental interference, data collection uncertainties.</li><li><strong>Impact:</strong> Makes it harder for the model to learn the true pattern and is a major cause of overfitting.</li></ul>'},occam:{title:"Occam's Razor",body:'<p>A philosophical principle: "Entities should not be multiplied without necessity."</p><strong class="text-slate-200 mt-3 block">Application in ML:</strong><p class="text-sm">Among competing models that explain the data equally well, the simplest one should be preferred. Simple models often generalize better and are closer to the truth. Regularization is a mathematical implementation of this principle.</p>'},coefficients:{title:"Coefficients",body:'<p>The weight parameters in front of each feature in a model.</p><strong class="text-slate-200 mt-3 block">In-depth Analysis:</strong><ul class="list-disc list-inside text-sm space-y-1 mt-1"><li><strong>Meaning:</strong> Reflect the influence and direction of each feature on the prediction.</li><li><strong>Sign of Overfitting:</strong> In high-degree polynomials, coefficients often become extremely large to force the curve through all data points.</li></ul>'},l2norm:{title:"L2 Norm",body:'<p>The square root of the sum of the squares of a vector\'s elements, also known as Euclidean length.</p><strong class="text-slate-200 mt-3 block">Core Formula:</strong><div class="my-2 p-2 bg-slate-800/50 rounded text-center font-mono text-slate-300 text-sm">||x||₂ = √(Σ xᵢ²)</div><strong class="text-slate-200 mt-3 block">Application in Regularization:</strong><p class="text-sm">In Ridge Regression, L2 regularization penalizes the L2 norm of the coefficient vector. This tends to shrink all coefficients evenly towards zero (but not exactly to zero), making the model smoother.</p>'},regularization:{title:"Regularization",body:"A technique used to prevent overfitting by adding a penalty term to the model's objective function to constrain its complexity (e.g., by keeping coefficients small). This forces the model to find a simpler, smoother solution, thus improving its ability to generalize."}};function r(){t.classList.add("opacity-0","pointer-events-none"),n.classList.add("opacity-0","pointer-events-none"),s.classList.add("scale-95")}document.querySelectorAll(".keyword-modal").forEach(e=>{e.addEventListener("click",()=>function(e){const a=l[e];a&&(o.textContent=a.title,i.innerHTML=a.body,t.classList.remove("opacity-0","pointer-events-none"),n.classList.remove("opacity-0","pointer-events-none"),s.classList.remove("scale-95"))}(e.dataset.term))}),a.addEventListener("click",r),t.addEventListener("click",r),document.addEventListener("keydown",e=>{"Escape"===e.key&&r()})}),refresh()</script>